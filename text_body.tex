\section{Introduction}


\subsection{Modal Analysis}
In \emph{linear} structural dynamics, \emph{Modal Analysis} is universally regarded as the pre-eminent solution for the identification or characterization of a structure or system. Modal analysis provides a means to perform said identification by studying the structure's \emph{modal properties or parameters}. Whether using mathematical modelling or experimental testing, modal analysis is a pillar for an engineer's understanding of a structure's response to various forms of excitation.  This understanding is crucial for safety and complying with standards or for research areas such as structural health monitoring or system identification.

Fundamentally, modal analysis is the decomposition of the complex oscillatory behaviours of structures and systems into several smaller components called \emph{modes}. Every mode is a numerical or mathematical representation of a specific vibration pattern corresponding to a \emph{natural frequency}, the frequency, or set of, at which a system tends to oscillate at subject to an initial displacement or velocity, and an associated \emph{mode shape}, a vector or function which describes the relative movement of the various degrees-of-freedom (DOFs) or axis points for each natural frequency, and \emph{damping ratio}, a unitless parameter describing the energy dissipation properties of the system at the natural frequencies. The modal properties are defined by the interaction of the system's physical properties, its mass, stiffness, and damping. These inherent properties guide the system's vibration when subject to external forcing or initial displacements or velocities.

Based on the theory, the standard procedure for modal analysis begins with forming the equations of motion (EOMs) that represent a system. Typically, the EOMs are second order matrix differential equations. Considering a system with an arbitrary number $N$, degrees-of-freedom as shown in figure \ref{fig:ndof-chain}. Interpreting Newton's second law as: $$\sum F_i = m_i\ddot{\mathbf{x}}_i$$ Where $F_i$ is a force acting on the $i$-th DOF, $m_i$ is the mass, and $\mathbf{x}_i$ is the coordinate of said DOF. Or the Euler-Lagrange equation as such: $$\frac{d}{dt}\left(\frac{\partial T}{\partial \dot{q}_i}\right) - \frac{\partial T}{\partial q_i} + \frac{\partial U}{\partial q_i} = Q_i$$
Where $q_i$ is a generalized coordinate, for this system one can take $q_i =\mathbf{x}_i$, $T$ is the system's kinetic energy, $U$ is the potential energy, and $Q_i$ are the non-conservative forces which impart or dissipate energy from the system. One finds that the equations of motion for the system are defined as shown in Equation \ref{eq:ndof-eoms}

\begin{equation}\label{eq:ndof-eoms}
    \begin{aligned}
        m_1\ddot{x}_1 + (c_1+c_2)\dot{x}_1 - c_2\dot{x}_2 + (k_1+k_2)x_1 -k_2x_2 & = F_1 \\
        m_2\ddot{x}_2 + (c_2+c_3)\dot{x}_1 - c_2\dot{x}_1 - c_3\dot{x_3} + (k_2+k_3)x_2 -k_2x_1 -k_3x_3 & = F_2\\
        \dots \hspace{5cm}\\
        m_N\ddot{x}_N + (c_N+c_{N+1})\dot{x}_N - c_{N-1}\dot{x}_{N-1} + (k_N+k_{N+1})x_N -k_{N-1}x_{N-1} & = F_{N}
    \end{aligned}
\end{equation}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Figures/n-dof-chain-sys.png}
    \caption{A "lumped-mass" system of $N$ degrees-of-freedom}
    \label{fig:ndof-chain}
\end{figure}
Assembling the physical parameters into respective matrices as highlighted in Equation \ref{eq:system-matrices}, the characteristic differential equation of the system is found.
\begin{equation}\label{eq:system-matrices}
    \begin{aligned}
        \relax [\mathbf{K}] &= \begin{bmatrix}
            k_1+k_2&-k_2 & 0 &\dots & 0\\
            -k_2&k_2+k_3&-k3&\dots &0\\
            0 & -k_3 & k_3+k_4& -k_4 &0\\
            \dots&\dots&\dots&\ddots &\dots\\
            0 & 0 & 0 & -k_{N} & k_{N}+k_{N+1}
        \end{bmatrix}\\
        [\mathbf{C}] &= \begin{bmatrix}
            c_1+c_2&-c_2 & 0 &\dots & 0\\
            -c_2&c_2+c_3&-c3&\dots &0\\
            0 & -c_3 & c_3+c_4& -c_4 &0\\
            \dots&\dots&\dots&\ddots &\dots\\
            0 & 0 & 0 & -c_{N} & c_{N}+c_{N+1}
        \end{bmatrix}\\
        [\mathbf{M}] &= \mathbf{diag}(m_i) \hspace{1cm} \forall i = 1,2,\dots,N
    \end{aligned}
\end{equation}
\begin{equation}\label{eq:general_damped_mdof}
    \therefore [\mathbf{M}]\mathbf{\ddot{x}}+[\mathbf{C}]\mathbf{\dot{x}}+[\mathbf{K}]\mathbf{x} = \mathbf{F}
\end{equation}

For the sake of simplicity, assume that the vibrating system presented is left to vibrate freely, and is undamped, meaning $\mathbf{F}$ and $\mathbf{C}$ are zero. If the solution of the presented differential equation is harmonic such that $\mathbf{x}(t) = \Psi e^{j\omega t}$, one finds that equation \ref{eq:general_damped_mdof} reduces to:
\begin{equation}
    ([\mathbf{K}] - \omega^2[\mathbf{M}])\Psi = 0
\end{equation}
By a rearrangement of the variables, one can manipulate the equation into becoming the general form for the eigenvalue problem:
\begin{equation}
    \begin{aligned}
        \relax [\mathbf{A}]& =  [\mathbf{M}]^{-1}[\mathbf{K}]\\
        [\mathbf{A}]&\Psi = \omega^2\Psi
    \end{aligned}
\end{equation}
Where $\mathbf{A}$ is the so-called dynamical matrix, $\omega^2$ is the eigenvalue — often referred to as an \emph{eigenfrequency} — of the matrix, and $\Psi$ is the corresponding eigenvector representing the modeshape vector.

% In systems with a finite number of degrees of freedom—often referred to as discrete systems—the modal analysis is performed using the dynamical matrix $[\mathbf{A}]$, which encapsulates the system's inertial and elastic properties. Building upon the discrete case, into systems which are modelled as continuous functions, the physical parameters of the systems are distributed spatially. This results into partial differential equation which governs the motion, where  finite dimensional matrices are then replaced with linear operators. Consequently, an eigenvalue problem is formed differently, in terms of a differential operator, where the eigenvalues are still correspondent to the natural frequency, and the respective eigenfunctions are the modeshapes in the spacial domain.

In systems with a finite number of degrees of freedom—often referred to as discrete systems—the modal analysis is performed using the dynamical matrix $[\mathbf{A}]$, which encapsulates the system's inertial and elastic properties. Building upon the discrete case, in systems that are modelled as continuous functions, the physical parameters of the system are distributed spatially. This results in a partial differential equation that governs the motion, where finite-dimensional matrices are replaced by linear operators. Consequently, an eigenvalue problem is formed in terms of a differential operator, with eigenvalues corresponding to the natural frequencies and the associated eigenfunctions representing the mode shapes in the spatial domain\footnote{An \emph{eigenvector}, or an \emph{eigenfunction}, of a matrix or linear operator defined on some vector/function space is any non-zero vector/function in said space that when multiplied or acted upon by the matrix/linear operator is equivalent to being multiplied by some scalar factor, said scalar factor is referred to as the \emph{eigenvalue}.}. This principle, applied to transversal vibration of an Euler-Bernoulli beam results in the eigenvalue problem defined in equation \ref{eq:eigenfunction-beam}:
\begin{equation}\label{eq:eigenfunction-beam}
    \Delta^2Y(x) = \beta^4Y(x)
\end{equation}
Where $\Delta$ is the Laplacian operator (second partial derivative in Cartesian coordinate system), and $\beta^4 = \frac{\omega^2}{c^2}$, in which $\omega$ is the natural frequency, and $c^2$ is the ratio of the flexural rigidity of the beam, and its inertia.

In both cases, discrete and continuous, by mathematically manipulating the EOMs governing the system, differential equations are reduced to eigenvalue problems—a solution that is not only mathematically elegant and robust, as it is applicable to all linear systems, but also linguistically apt, given that "eigen" means "one's own". However, while this approach to modal analysis may be elegant, its practical applications rarely exist. Real world vibrating structures and systems rarely conform to the idealized assumptions of lumped-mass systems or Euler-Bernoulli beams with known boundary conditions, this limitation can be attributed to more complex geometries, or internal interactions between the components of a system. This limitation has incentivized academics and practitioners to approach modal analysis differently.  





\pagebreak
Report Story:\\
\textbf{Structural Dynamics in engineering}
\begin{itemize}
    \item How studying structural mechanics has helped us have safer, lighter, greener structures.
    \item Modal Analysis, is regarded as \textbf{the} solution for linear structural dynamics.
    \item Maths of modal analysis:
    \begin{itemize}
        \item EOM formulation.
        \item Eigendecomposition of state matrices.
        \item FRF in modal terms. (refer to plscf solution using that)
    \end{itemize}
    \item This is in various industries, home appliances, aero, civil/structural, acoustics etc.
    \item Experimental Modal Analysis king.
    \item Curve-fitting methods for modal analysis.
    \item The need for algorithms in practice.
\end{itemize}

Onto software usage in engineering contexts
\begin{itemize}
    \item engineers consistently rely on software tools, this is great as it streamlines the important processes.
    \item Important aspects of software dev. :
    \begin{itemize}
        \item logic/control flow
        \item complexities and big O notation
        \item unit testing and integration testing.
        \item version control.
        \item foss vs. prop. discuss why it's cheaper in long run, and better for everyone involved.
    \end{itemize}
    \item Revisit the aims and objectives.
\end{itemize}

\section{Algorithms / development:}
\textbf{maths-y bit}
\begin{itemize}
    \item lsce (brief)
    \item lscf (brief)
    \item plscf (important bits and refer to appendix for full derivation, use own notation and wording).
    \item Why the companion matrix solution works. $\mathbf{eig}(C(p)) = \lambda_i \rightarrow p(\lambda) = 0$
    \item here one must explain what poles are for a system.
    \item lsfd for modeshapes.
\end{itemize}

\textbf{software-y bit}
\begin{itemize}
    \item time complexity optimization. discuss that O notation doesn't always equal less time.
    \item unit testing, explain pytest stuff and fixturing and bla bla bla.
    \item using numpy (BLAS routines/subroutines)
    \item user facing code.
    \item formatting guidelines.
\end{itemize}



\section{Results}

\begin{itemize}
    \item plscf on simulated modal data.
    \begin{itemize}
        \item clean
        \item noisy
        \item slightly nonlinear data (mimo where $H_{ij} \approx H_{ji}$ but $H_{ij} \neq H_{ji}$)
        \item high dofs.
    \end{itemize}
    \item plscf on actual lab data.
    \item adam's plscf vs siemens lms polymax on same dataset.
    \item interpretation of stabilization diagram.
\end{itemize}


\begin{lstlisting}[style={Python}]
import numpy as np

def _make_polynomial_basis_fcn(
    polynomial_order: int, frequency_vector: np.ndarray, sampling_frequency: float
):
    """Function that creates a Polynomial Basis Function matrix

    Args:
        polynomial_order (int): Order of the polynomial created. i.e. if 2 then P(x) = a0 * x^0  +  a1 * x^1 + a2 * x^2
        in the case of pLSCF, Omega(w) = P(e^{jw _delta t})

        frequency_vector (np.ndarray): vector of frequencies measured or simulated, can be hz or rads-1.
        MUST be either a row or column vector/1D Array

    Returns:
        Polynomial basis function matrix.
    """
    # the polynomial basis function is actually the vandermonde matrix for the polynomials, A and B.
    dt = 1 / sampling_frequency  # Sampling rate
    s = np.exp(1.j*frequency_vector*dt) # this is the "x" in the polynomial
    return np.vander(x=s,N=polynomial_order+1,increasing=True)    
\end{lstlisting}

\pagebreak





Consider the Jacobian matrix, for a system with $n_{outputs} = 3$:
\begin{equation}
    J = \begin{pmatrix}
        X_1 & 0 & 0 & Y_1\\
        0 & X_2& 0 & Y_2\\
        0 & 0 & X_3 & Y_3
    \end{pmatrix}    
\end{equation}

\begin{equation}
    J^HJ = \begin{pmatrix}
        X_{1}^HX_1 & 0 & 0 & X_{1}^HY_1\\
        0 & X_{2}^HX_2 & 0 & X_{1}^HY_2\\
        0 & 0 & X_{2}^HX_2 & X_{1}^HY_3\\
        X_{1}^*Y_{1}^T & X_{2}^*Y_{2}^T & X_{3}^*Y_{3}^T & Y_{1}^HY_1+Y_{2}^HY_2+Y_{3}^HY_3\\
    \end{pmatrix}
\end{equation}
if:
$$    R_o = Re(X_{o}^HX_o) $$
$$    S_o = Re(X_{o}^HY_o)$$
$$    T_o = Re(Y_{o}^HY_o)$$
\begin{equation}
    2Re(J^HJ)\theta = 2Re\begin{pmatrix}
        X_{1}^HX_1 & 0 & 0 & X_{1}^HY_1\\
        0 & X_{2}^HX_2 & 0 & X_{1}^HY_2\\
        0 & 0 & X_{2}^HX_2 & X_{1}^HY_3\\
        X_{1}^*Y_{1}^T & X_{2}^*Y_{2}^T & X_{3}^*Y_{3}^T & Y_{1}^HY_1+Y_{2}^HY_2+Y_{3}^HY_3\\
    \end{pmatrix}
    \begin{pmatrix}
        \beta_1\\
        \beta_2\\
        \beta_3\\
        \alpha
    \end{pmatrix} 
\end{equation}
\begin{equation}
    = 
    2 \begin{pmatrix}
        R_1\beta_1+S_1\alpha\\
        R_2\beta_2+S_2\alpha\\
        R_3\beta_3+S_3\alpha\\
        S_{1}^T\beta_1+S_{2}^T\beta_2+S_{3}^T\beta_3 +(T_1+T_2+T_3)\alpha 
    \end{pmatrix}
\end{equation}

which corresponds to the solutions in the normal equations in terms of alpha and beta.


\begin{equation}
    l^{LS}(\theta) = tr\{\theta^TRe(J^HJ)\theta\}
\end{equation}

from vector calculus, if
\begin{equation}
    \mathbf{f}= \mathbf{x^TBx}
\end{equation}
then,
\begin{equation}
    \frac{\partial \mathbf{f}}{\partial \mathbf{x}} = 2\mathbf{Bx}
\end{equation}

then the normal equation for polymax should be:
\begin{equation}
    \frac{\partial l^{LS}}{\partial \theta} = 2Re(J^HJ)\theta
\end{equation}